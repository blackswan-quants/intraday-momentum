{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a673534c",
   "metadata": {},
   "source": [
    "### Importing cleaned dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2410d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\giuli\\Repositories\\intraday-momentum\\src\")\n",
    "from classes.metrics.metrics import MetricsCalculator\n",
    "from classes.backtest.engine import BacktestEngine  \n",
    "from classes.backtest.default import BacktestDefaults \n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    force=True,   # <-- allow printing in jupyter notebooks\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a66305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 194105 entries, 2023-10-30 09:30:00 to 2025-10-27 15:59:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   volume  194105 non-null  float64\n",
      " 1   open    194105 non-null  float64\n",
      " 2   high    194105 non-null  float64\n",
      " 3   low     194105 non-null  float64\n",
      " 4   close   194105 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 8.9 MB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 500 entries, 2023-10-27 05:00:00+00:00 to 2025-10-24 05:00:00+00:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   volume  500 non-null    int64  \n",
      " 1   open    500 non-null    float64\n",
      " 2   high    500 non-null    float64\n",
      " 3   low     500 non-null    float64\n",
      " 4   close   500 non-null    float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 23.4 KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   caldt     8 non-null      object \n",
      " 1   dividend  8 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 260.0+ bytes\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 522 entries, 2023-10-27 16:00:00 to 2025-11-25 16:00:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   volume  522 non-null    int64  \n",
      " 1   open    522 non-null    float64\n",
      " 2   high    522 non-null    float64\n",
      " 3   low     522 non-null    float64\n",
      " 4   close   522 non-null    float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 24.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Load files\n",
    "df_spy = pd.read_pickle(\"C:\\\\Users\\\\giuli\\\\Repositories\\\\intraday-momentum\\\\data\\\\cleaned\\\\SPY_1min_20231027_20251027.pkl\")  \n",
    "df_vixx = pd.read_pickle(\"C:/Users/giuli/Repositories/intraday-momentum/data/cleaned/^VIX_1day_20231027_20251027.pkl\")\n",
    "df_dividends = pd.read_csv(\"C:\\\\Users\\\\giuli\\\\Repositories\\\\intraday-momentum\\\\data\\\\cleaned\\\\SPY_dividends_20231027_20250919.csv\")\n",
    "df_spy_daily = pd.read_pickle(\"C:/Users/giuli/Repositories/intraday-momentum/data/cleaned/SPY_daily_from27-10-2023.pkl\")\n",
    "\n",
    "# Print information about the dataframes\n",
    "df_spy.info()\n",
    "print(\"\\n\")\n",
    "df_vixx.info()\n",
    "print(\"\\n\")\n",
    "df_dividends.info()\n",
    "print(\"\\n\")\n",
    "df_spy_daily.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9e2d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:48:44,758 | INFO | df_spy: index is a valid DatetimeIndex with timezone=None.\n",
      "2025-12-01 13:48:44,758 | INFO | df_vixx: index is a valid DatetimeIndex with timezone=UTC.\n",
      "2025-12-01 13:48:44,760 | INFO | df_spy_daily: index is a valid DatetimeIndex with timezone=None.\n"
     ]
    }
   ],
   "source": [
    "dfs = {\n",
    "    \"df_spy\": df_spy,\n",
    "    \"df_vixx\": df_vixx,\n",
    "    \"df_spy_daily\": df_spy_daily,\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise TypeError(f\"{name}: index must be a DatetimeIndex.\")\n",
    "    else:\n",
    "        logger.info(f\"{name}: index is a valid DatetimeIndex with timezone={df.index.tz}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69343066",
   "metadata": {},
   "source": [
    "Two dfs have no timezone, so we need to make sure everything is uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b30cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:48:44,956 | INFO | df_spy: index is a valid DatetimeIndex (tz=UTC)\n",
      "2025-12-01 13:48:44,956 | INFO | df_vixx: index is a valid DatetimeIndex (tz=UTC)\n",
      "2025-12-01 13:48:44,956 | INFO | df_spy_daily: index is a valid DatetimeIndex (tz=UTC)\n"
     ]
    }
   ],
   "source": [
    "dfs = {\n",
    "    \"df_spy\": df_spy,\n",
    "    \"df_vixx\": df_vixx,\n",
    "    \"df_spy_daily\": df_spy_daily\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    # Ensure index is DatetimeIndex\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Localize naive timestamps (assuming US/Eastern for intraday and daily SPY; VIX depends)\n",
    "    if df.index.tz is None:\n",
    "        if name in [\"df_spy\", \"df_spy_daily\"]:\n",
    "            df.index = df.index.tz_localize(\"US/Eastern\")\n",
    "        else:  \n",
    "            df.index = df.index.tz_localize(\"UTC\")  \n",
    "\n",
    "    # Convert to common timezone UTC\n",
    "    df.index = df.index.tz_convert(\"UTC\")\n",
    "\n",
    "    # Assign back to dict\n",
    "    dfs[name] = df\n",
    "\n",
    "    # Log result\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        logger.info(f\"{name}: index is a valid DatetimeIndex (tz={df.index.tz})\")\n",
    "    else:\n",
    "        logger.warning(f\"{name}: index is NOT a DatetimeIndex (type={type(df.index)})\")\n",
    "\n",
    "#reassign to original variables\n",
    "df_spy = dfs[\"df_spy\"]\n",
    "df_vixx = dfs[\"df_vixx\"]\n",
    "df_spy_daily = dfs[\"df_spy_daily\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4d108",
   "metadata": {},
   "source": [
    "### Add key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3608c777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Datetime",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c0f317dc-2990-44d0-9bc8-bda842821ce0",
       "rows": [
        [
         "2023-10-31 15:20:00+00:00",
         "114037.0",
         "416.035",
         "416.07",
         "415.83",
         "415.88"
        ],
        [
         "2023-10-31 15:21:00+00:00",
         "113127.0",
         "415.88",
         "415.99",
         "415.72",
         "415.8"
        ],
        [
         "2023-10-31 15:22:00+00:00",
         "133653.0",
         "415.8",
         "415.94",
         "415.765",
         "415.91"
        ],
        [
         "2023-10-31 15:23:00+00:00",
         "73109.0",
         "415.91",
         "415.91",
         "415.735",
         "415.77"
        ],
        [
         "2023-10-31 15:24:00+00:00",
         "168774.0",
         "415.78",
         "415.79",
         "415.6002",
         "415.75"
        ],
        [
         "2023-10-31 15:25:00+00:00",
         "128031.0",
         "415.76",
         "416.06",
         "415.68",
         "415.98"
        ],
        [
         "2023-10-31 15:26:00+00:00",
         "136299.0",
         "415.98",
         "416.33",
         "415.98",
         "416.3"
        ],
        [
         "2023-10-31 15:27:00+00:00",
         "102300.0",
         "416.32",
         "416.35",
         "416.13",
         "416.27"
        ],
        [
         "2023-10-31 15:28:00+00:00",
         "83196.0",
         "416.27",
         "416.31",
         "416.1006",
         "416.13"
        ],
        [
         "2023-10-31 15:29:00+00:00",
         "81919.0",
         "416.13",
         "416.15",
         "415.65",
         "415.71"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:20:00+00:00</th>\n",
       "      <td>114037.0</td>\n",
       "      <td>416.035</td>\n",
       "      <td>416.07</td>\n",
       "      <td>415.8300</td>\n",
       "      <td>415.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:21:00+00:00</th>\n",
       "      <td>113127.0</td>\n",
       "      <td>415.880</td>\n",
       "      <td>415.99</td>\n",
       "      <td>415.7200</td>\n",
       "      <td>415.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:22:00+00:00</th>\n",
       "      <td>133653.0</td>\n",
       "      <td>415.800</td>\n",
       "      <td>415.94</td>\n",
       "      <td>415.7650</td>\n",
       "      <td>415.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:23:00+00:00</th>\n",
       "      <td>73109.0</td>\n",
       "      <td>415.910</td>\n",
       "      <td>415.91</td>\n",
       "      <td>415.7350</td>\n",
       "      <td>415.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:24:00+00:00</th>\n",
       "      <td>168774.0</td>\n",
       "      <td>415.780</td>\n",
       "      <td>415.79</td>\n",
       "      <td>415.6002</td>\n",
       "      <td>415.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:25:00+00:00</th>\n",
       "      <td>128031.0</td>\n",
       "      <td>415.760</td>\n",
       "      <td>416.06</td>\n",
       "      <td>415.6800</td>\n",
       "      <td>415.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:26:00+00:00</th>\n",
       "      <td>136299.0</td>\n",
       "      <td>415.980</td>\n",
       "      <td>416.33</td>\n",
       "      <td>415.9800</td>\n",
       "      <td>416.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:27:00+00:00</th>\n",
       "      <td>102300.0</td>\n",
       "      <td>416.320</td>\n",
       "      <td>416.35</td>\n",
       "      <td>416.1300</td>\n",
       "      <td>416.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:28:00+00:00</th>\n",
       "      <td>83196.0</td>\n",
       "      <td>416.270</td>\n",
       "      <td>416.31</td>\n",
       "      <td>416.1006</td>\n",
       "      <td>416.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31 15:29:00+00:00</th>\n",
       "      <td>81919.0</td>\n",
       "      <td>416.130</td>\n",
       "      <td>416.15</td>\n",
       "      <td>415.6500</td>\n",
       "      <td>415.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             volume     open    high       low   close\n",
       "Datetime                                                              \n",
       "2023-10-31 15:20:00+00:00  114037.0  416.035  416.07  415.8300  415.88\n",
       "2023-10-31 15:21:00+00:00  113127.0  415.880  415.99  415.7200  415.80\n",
       "2023-10-31 15:22:00+00:00  133653.0  415.800  415.94  415.7650  415.91\n",
       "2023-10-31 15:23:00+00:00   73109.0  415.910  415.91  415.7350  415.77\n",
       "2023-10-31 15:24:00+00:00  168774.0  415.780  415.79  415.6002  415.75\n",
       "2023-10-31 15:25:00+00:00  128031.0  415.760  416.06  415.6800  415.98\n",
       "2023-10-31 15:26:00+00:00  136299.0  415.980  416.33  415.9800  416.30\n",
       "2023-10-31 15:27:00+00:00  102300.0  416.320  416.35  416.1300  416.27\n",
       "2023-10-31 15:28:00+00:00   83196.0  416.270  416.31  416.1006  416.13\n",
       "2023-10-31 15:29:00+00:00   81919.0  416.130  416.15  415.6500  415.71"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy[500:510]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091762c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure df_spy index is DatetimeIndex\n",
    "if not isinstance(df_spy.index, pd.DatetimeIndex):\n",
    "    df_spy.index = pd.to_datetime(df_spy.index)\n",
    "\n",
    "# Add 'day' column for dividends merge\n",
    "df_spy[\"day\"] = df_spy.index.date\n",
    "\n",
    "project_root = Path().resolve().parents[0]  # adjust if needed\n",
    "data_path = project_root / \"data\" / \"cleaned\" / \"SPY_dividends_20231027_20250919.csv\"\n",
    "\n",
    "dividends = pd.read_csv(data_path)\n",
    "\n",
    "dividends[\"caldt\"] = pd.to_datetime(dividends[\"caldt\"]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a34c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:48:45,062 | INFO | Starting computation of market microstructure metrics...\n",
      "2025-12-01 13:48:45,556 | ERROR | Error computing metrics.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\giuli\\Repositories\\intraday-momentum\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'Datetime'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\giuli\\Repositories\\intraday-momentum\\src\\classes\\metrics\\metrics.py\", line 83, in from_clean_df\n",
      "    df_daily = self.compute_intraday_profiles(df)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\giuli\\Repositories\\intraday-momentum\\src\\classes\\metrics\\metrics.py\", line 147, in compute_intraday_profiles\n",
      "    df[\"Datetime\"].dt.hour * 60 + df[\"Datetime\"].dt.minute\n",
      "    ~~^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giuli\\Repositories\\intraday-momentum\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4113, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giuli\\Repositories\\intraday-momentum\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'Datetime'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Metric computation failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giuli\\Repositories\\intraday-momentum\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Repositories\\intraday-momentum\\src\\classes\\metrics\\metrics.py:83\u001b[39m, in \u001b[36mMetricsCalculator.from_clean_df\u001b[39m\u001b[34m(self, df, save)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.compute_vwap(df)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     df_daily = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_intraday_profiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Repositories\\intraday-momentum\\src\\classes\\metrics\\metrics.py:147\u001b[39m, in \u001b[36mMetricsCalculator.compute_intraday_profiles\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mminute_of_day\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n\u001b[32m    146\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mminute_of_day\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDatetime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.dt.hour * \u001b[32m60\u001b[39m + df[\u001b[33m\"\u001b[39m\u001b[33mDatetime\u001b[39m\u001b[33m\"\u001b[39m].dt.minute\n\u001b[32m    148\u001b[39m     ).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    151\u001b[39m     df.groupby(\u001b[33m\"\u001b[39m\u001b[33mminute_of_day\u001b[39m\u001b[33m\"\u001b[39m)[[\u001b[33m\"\u001b[39m\u001b[33mvwap\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRV\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBV\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlog_returns\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m    152\u001b[39m     .mean()\n\u001b[32m    153\u001b[39m     .astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m    154\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giuli\\Repositories\\intraday-momentum\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giuli\\Repositories\\intraday-momentum\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'Datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Compute metrics\u001b[39;00m\n\u001b[32m      2\u001b[39m mc = MetricsCalculator()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_clean_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_spy_daily\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m mc._validate_input(df_spy_daily)\n\u001b[32m      6\u001b[39m mc.compute_intraday_cum_vwap(df_spy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Repositories\\intraday-momentum\\src\\classes\\metrics\\metrics.py:87\u001b[39m, in \u001b[36mMetricsCalculator.from_clean_df\u001b[39m\u001b[34m(self, df, save)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     86\u001b[39m     \u001b[38;5;28mself\u001b[39m.logger.error(\u001b[33m\"\u001b[39m\u001b[33mError computing metrics.\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMetric computation failed.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m.quality_check(df, df_daily)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save:\n",
      "\u001b[31mRuntimeError\u001b[39m: Metric computation failed."
     ]
    }
   ],
   "source": [
    "# Compute metrics\n",
    "mc = MetricsCalculator()\n",
    "mc.from_clean_df(df_spy_daily)\n",
    "mc._validate_input(df_spy_daily)\n",
    "\n",
    "mc.compute_intraday_cum_vwap(df_spy)\n",
    "mc.compute_move_open(df_spy)\n",
    "mc.compute_daily_returns_and_vol(df_spy)\n",
    "mc.compute_minute_features(df_spy)  # requires DatetimeIndex\n",
    "mc.merge_dividends(df_spy, dividends)\n",
    "mc.quality_check(df_spy, df_spy_daily)\n",
    "\n",
    "mc.logger.info(\"All SPY metrics successfully computed.\")\n",
    "\n",
    "df_spy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb790d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 194105 entries, 2023-10-30 13:30:00+00:00 to 2025-10-27 19:59:00+00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   volume  194105 non-null  float64\n",
      " 1   open    194105 non-null  float64\n",
      " 2   high    194105 non-null  float64\n",
      " 3   low     194105 non-null  float64\n",
      " 4   close   194105 non-null  float64\n",
      " 5   day     194105 non-null  object \n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 10.4+ MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e70480b8-60f2-4f48-b7c5-f7d4c00c7c34",
       "rows": [
        [
         "volume",
         "0"
        ],
        [
         "open",
         "0"
        ],
        [
         "high",
         "0"
        ],
        [
         "low",
         "0"
        ],
        [
         "close",
         "0"
        ],
        [
         "day",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "volume    0\n",
       "open      0\n",
       "high      0\n",
       "low       0\n",
       "close     0\n",
       "day       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_spy.info()\n",
    "df_spy.describe()\n",
    "df_spy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb885c63",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      1\u001b[39m defaults = BacktestDefaults(\n\u001b[32m      2\u001b[39m     minute_path=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     daily_path=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     max_leverage=\u001b[32m4.0\u001b[39m,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m engine = BacktestEngine()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m trade_log_df, daily_pnl_df, equity_curve_df = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43masdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Repositories\\intraday-momentum\\src\\classes\\backtest\\engine.py:636\u001b[39m, in \u001b[36mBacktestEngine.run_backtest\u001b[39m\u001b[34m(self, params)\u001b[39m\n\u001b[32m    633\u001b[39m max_leverage: \u001b[38;5;28mfloat\u001b[39m = \u001b[38;5;28mfloat\u001b[39m(params.get(\u001b[33m\"\u001b[39m\u001b[33mmax_leverage\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    635\u001b[39m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m mdf: pd.DataFrame = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_minute_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminute_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m spy_daily: Optional[pd.DataFrame] = \u001b[38;5;28mself\u001b[39m._load_daily_data(daily_path)\n\u001b[32m    639\u001b[39m groups = mdf.groupby(\u001b[33m\"\u001b[39m\u001b[33mday\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Repositories\\intraday-momentum\\src\\classes\\backtest\\engine.py:393\u001b[39m, in \u001b[36mBacktestEngine._load_minute_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_load_minute_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) -> pd.DataFrame:\n\u001b[32m    373\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03m    Load and validate minute-level data.\u001b[39;00m\n\u001b[32m    375\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m \u001b[33;03m        If required columns are missing.\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n\u001b[32m    395\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcleaned_df.pkl must include a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m column.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giuli\\Repositories\\intraday-momentum\\.venv\\Lib\\site-packages\\pandas\\io\\pickle.py:185\u001b[39m, in \u001b[36mread_pickle\u001b[39m\u001b[34m(filepath_or_buffer, compression, storage_options)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m4    4    9\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m excs_to_catch = (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giuli\\Repositories\\intraday-momentum\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "\n",
    "defaults = BacktestDefaults(\n",
    "    minute_path=\"\",\n",
    "    daily_path=\"\",\n",
    "    initial_aum=100_000.0,\n",
    "    commission_rate=0.0035,\n",
    "    min_comm_per_order=0.35,\n",
    "    slippage_bps=0,\n",
    "    band_mult=1.0,\n",
    "    trade_freq=30,\n",
    "    sizing_type=\"vol_target\",\n",
    "    target_vol=0.02,\n",
    "    max_leverage=4.0,\n",
    ")\n",
    "\n",
    "engine = BacktestEngine()\n",
    "trade_log_df, daily_pnl_df, equity_curve_df = engine.run_backtest(asdict(defaults))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intraday-momentum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
